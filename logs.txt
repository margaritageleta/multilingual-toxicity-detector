# Distilbert one layer 

EPOCHS = 3
BATCH_SIZE = 16 
OPTIMIZER = 'adam'
LR = 0.0001
DROPOUT = 0.5

Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_word_ids (InputLayer)  [(None, 192)]             0         
_________________________________________________________________
tf_distil_bert_model (TFDist ((None, 192, 768),)       134734080 
_________________________________________________________________
tf_op_layer_strided_slice (T [(None, 768)]             0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 768)               0         
_________________________________________________________________
toxicity_prob_head (Dense)   (None, 1)                 769       
=================================================================
Total params: 134,734,849
Trainable params: 134,734,849
Non-trainable params: 0
_________________________________________________________________

Epoch 1/3
19288/19288 [==============================] - 4100s 213ms/step - loss: 0.0451 - accuracy: 0.9814 - auc: 0.9985 - val_loss: 1.0545 - val_accuracy: 0.1538 - val_auc: 0.5000
Epoch 3/3
19235/19288 [============================>.] - ETA: 11s - loss: 0.0447 - accuracy: 0.9824 - auc: 0.9985

12322.838149785995

Epoch 1/6
500/500 [==============================] - 106s 211ms/step - loss: 0.4400 - accuracy: 0.8409 - auc: 0.4954
Epoch 2/6
500/500 [==============================] - 105s 211ms/step - loss: 0.4347 - accuracy: 0.8462 - auc: 0.4849
Epoch 3/6
500/500 [==============================] - 106s 211ms/step - loss: 0.4326 - accuracy: 0.8462 - auc: 0.4998
Epoch 4/6
500/500 [==============================] - 106s 211ms/step - loss: 0.4325 - accuracy: 0.8462 - auc: 0.4995
Epoch 5/6
500/500 [==============================] - 105s 211ms/step - loss: 0.4327 - accuracy: 0.8462 - auc: 0.4921
Epoch 6/6
500/500 [==============================] - 105s 211ms/step - loss: 0.4330 - accuracy: 0.8462 - auc: 0.4841


634.3936896324158


============================================================================================================

# Distilbert one layer

EPOCHS = 3
BATCH_SIZE = 16 
OPTIMIZER = 'adam'
LR = 0.0001
DROPOUT = 0.35

Training time: 25283.105884552002
Average train accuracy: 0.9820559620857239
Validation time: 1305.8294825553894
Average validation accuracy: 0.8454999923706055


============================================================================================================
# Distilbert one layer

EPOCHS = 3
BATCH_SIZE = 16 
OPTIMIZER = 'adam'
LR = 0.0001
DROPOUT = 0

Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_word_ids (InputLayer)  [(None, 192)]             0         
_________________________________________________________________
tf_distil_bert_model (TFDist ((None, 192, 768),)       134734080 
_________________________________________________________________
tf_op_layer_strided_slice (T [(None, 768)]             0         
_________________________________________________________________
toxicity_prob_head (Dense)   (None, 1)                 769       
=================================================================
Total params: 134,734,849
Trainable params: 134,734,849
Non-trainable params: 0
_________________________________________________________________

Train for 19288 steps, validate for 500 steps
Epoch 1/3
19288/19288 [==============================] - 2976s 154ms/step - loss: 0.0381 - accuracy: 0.9841 - auc: 0.9989 - val_loss: 0.7705 - val_accuracy: 0.1538 - val_auc: 0.5000
Epoch 2/3
19288/19288 [==============================] - 2971s 154ms/step - loss: 0.0452 - accuracy: 0.9812 - auc: 0.9986 - val_loss: 1.0292 - val_accuracy: 0.1538 - val_auc: 0.5000
Epoch 3/3
19288/19288 [==============================] - 2987s 155ms/step - loss: 0.0459 - accuracy: 0.9809 - auc: 0.9985 - val_loss: 1.0423 - val_accuracy: 0.1538 - val_auc: 0.5000

Training time: 8933.488419532776
Average train accuracy: 0.9820786118507385
Average train accuracy: 0.9986586570739746
Validation time: 450.46697187423706
Average validation accuracy: 0.8451250195503235
Average validation accuracy: 0.49217689037323

============================================================================================================
Deep distilbert

# Hyperparameters
EPOCHS = 3
BATCH_SIZE = 16 
OPTIMIZER = 'adam'
LR = 0.0001
DROPOUT = 0.35

Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_word_ids (InputLayer)  [(None, 192)]             0         
_________________________________________________________________
tf_distil_bert_model_3 (TFDi ((None, 192, 768),)       134734080 
_________________________________________________________________
tf_op_layer_strided_slice_3  [(None, 768)]             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               393728    
_________________________________________________________________
dropout_79 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_80 (Dropout)         (None, 256)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 128)               32896     
_________________________________________________________________
dropout_81 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 64)                8256      
_________________________________________________________________
dropout_82 (Dropout)         (None, 64)                0         
_________________________________________________________________
dense_7 (Dense)              (None, 32)                2080      
_________________________________________________________________
dropout_83 (Dropout)         (None, 32)                0         
_________________________________________________________________
toxicity_prob_head (Dense)   (None, 1)                 33        
=================================================================
Total params: 135,302,401
Trainable params: 135,302,401
Non-trainable params: 0
_________________________________________________________________

Training time: 9992.300254821777
Average train accuracy: 0.9813819527626038
Average train auc: 0.9981392025947571
Validation time: 523.7079792022705
Average validation accuracy: 0.8432292342185974
Average validation auc: 0.5000764727592468


===========================================================================================================
xlm Roberta

Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_word_ids (InputLayer)  [(None, 192)]             0         
_________________________________________________________________
tf_roberta_model (TFRobertaM ((None, 192, 1024), (None 559890432 
_________________________________________________________________
tf_op_layer_strided_slice (T [(None, 1024)]            0         
_________________________________________________________________
dropout_74 (Dropout)         (None, 1024)              0         
_________________________________________________________________
toxicity_prob_head (Dense)   (None, 1)                 1025      
=================================================================
Total params: 559,891,457
Trainable params: 559,891,457
Non-trainable params: 0
_________________________________________________________________


===========================================================================================================
deep distilbert

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_word_ids (InputLayer)  [(None, 256)]             0         
_________________________________________________________________
tf_distil_bert_model_2 (TFDi ((None, 256, 768),)       134734080 
_________________________________________________________________
tf_op_layer_strided_slice_1  [(None, 768)]             0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               393728    
_________________________________________________________________
dropout_62 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_63 (Dropout)         (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 128)               32896     
_________________________________________________________________
dropout_64 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 64)                8256      
_________________________________________________________________
dropout_65 (Dropout)         (None, 64)                0         
_________________________________________________________________
dense_9 (Dense)              (None, 32)                2080      
_________________________________________________________________
dropout_66 (Dropout)         (None, 32)                0         
_________________________________________________________________
toxicity_prob_head (Dense)   (None, 1)                 33        
=================================================================
Total params: 135,302,401
Trainable params: 135,302,401
Non-trainable params: 0
_________________________________________________________________

Training time: 12806.63016796112
Average train accuracy: 0.979515552520752




